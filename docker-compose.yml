services:
  freva-gpt2-backend:
    image: freva-gpt2-backend-${INSTANCE_NAME:?Instance name must be set in the .env file to differentiate between instances}
    build:
      context: .
      dockerfile: dockerfiles/chatbot-backend/Dockerfile
      cgroup_manager: cgroupfs # TODO: This is giving some trouble in development, is it really needed?
      tags:
        - freva-gpt2-backend:${INSTANCE_NAME}
    hostname: freva-gpt2-backend-instance-${INSTANCE_NAME}
    ports:
      - "${TARGET_PORT:-8502}:${BACKEND_PORT:-8502}" # If either is unset, the default value will be used.
    volumes:
      - /work:/work:ro
      - /container/da/freva-gpt-backend-links/${INSTANCE_NAME}/logs:/app/logs
      - /container/da/freva-gpt-backend-links/${INSTANCE_NAME}/threads:/app/threads
      - /container/da/freva-gpt-backend-links/${INSTANCE_NAME}/target:/app/target
      - /home/b/b380001/freva-gpt2-backend/testdata:/data/inputFiles # Deprecated, once used for test data before freva support was added. Now used for debugging.
      - /container/da/freva-gpt-backend-links/${INSTANCE_NAME}/python_pickles:/app/python_pickles
    networks:
      - freva-gpt
  ollama: # Ollama is only for the backend and not accessible from the outside. Port 11434 is not exposed.
    image: ollama/ollama
    hostname: ollama-instance-${INSTANCE_NAME}
    volumes:
      - /container/da/freva-gpt-ollama-LLMs/.ollama:/root/.ollama
    networks:
      - freva-gpt
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

networks:
  freva-gpt:
    driver: bridge
# The subnet is not set to avoid conflicts with other potentially running networks on the same machine.
# Note: Named networks by default aren't shared between different docker-compose projects, even if they have the same name, as long as they are in separate directories.

